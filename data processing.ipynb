{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirorezka/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from mean_f1 import *  ## library with mean_f1 metric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import xgboost as xgb\n",
    " \n",
    "\n",
    "from lxml import etree\n",
    "from lxml import objectify\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "N_PROCS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "##   Reading XML data\n",
    "\n",
    "def parse_tree_struct((xml_root, k)):\n",
    "\n",
    "    dt_row = dict()   ## for storing rows\n",
    "    dt_industr =  dict()  ## for storing industries\n",
    "    \n",
    "    b_childs = etree.fromstring(xml_root)\n",
    "    dt_row['id'] = b_childs.get(\"id\")\n",
    "    b_childs = b_childs.getchildren()\n",
    "    \n",
    "\n",
    "    for tree_elem in b_childs:\n",
    "        tag_val = tree_elem.tag\n",
    "        num_val = tree_elem.text\n",
    "        dt_row[tag_val] = num_val\n",
    "\n",
    "        if tree_elem.tag == 'term':\n",
    "            new_tag = tree_elem.getchildren()[0].tag\n",
    "            dt_row[new_tag] = tree_elem.getchildren()[0].text\n",
    "\n",
    "        if tree_elem.tag == 'requirement':\n",
    "            new_tag = tree_elem.getchildren()[0].tag\n",
    "            dt_row[new_tag] = tree_elem.getchildren()[0].text\n",
    "\n",
    "        if tree_elem.tag == 'industries':\n",
    "            for ind_elem in tree_elem.getchildren():\n",
    "                dt_industr [ind_elem.text] = 1\n",
    "\n",
    "    dt_row = pd.Series(dt_row)\n",
    "    dt_row['y_industr'] = dt_industr\n",
    "    \n",
    "    return dt_row \n",
    "\n",
    "def read_data_gz(filename_str):\n",
    "    \n",
    "    # initiate parser\n",
    "    parser = etree.XMLParser(ns_clean=True, encoding='utf-8')\n",
    "    data_train_tree = etree.parse(filename_str,parser)\n",
    "\n",
    "    # set up column names\n",
    "    col_names = ['id','update-date','industries','job-name','salary','currency','employment','schedule','description','experience','contract','y_industr']\n",
    "\n",
    "    root = data_train_tree.getroot().getchildren() ##[0:1000] ## generate sample   \n",
    "    root_data_size = len(root)\n",
    "    \n",
    "    ## processing xml data in pool\n",
    "    pool = Pool(processes = N_PROCS)\n",
    "    dt_data = pool.map(parse_tree_struct, zip(map (etree.tostring, root),\n",
    "                                                    np.array(range(root_data_size))))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "        \n",
    "    dt_data = pd.DataFrame(dt_data,columns=col_names)    \n",
    "    tt = map (lambda x: pd.Series(dict(x)), dt_data['y_industr'])\n",
    "    y_train = pd.DataFrame(tt)\n",
    "    \n",
    "    dt_data = dt_data.drop('y_industr',axis = 1)\n",
    "    ## dt_train = dt_train.append(dt_row, ignore_index=True)\n",
    "    ## y_train = y_train.append(dt_industr, ignore_index=True)\n",
    "        \n",
    "    return dt_data, y_train ##dt_train, y_train\n",
    "    \n",
    "dt_train, y_class = read_data_gz (\"Data/train.xml.gz\")\n",
    "dt_test, y_test = read_data_gz (\"Data/test.xml.gz\")\n",
    "\n",
    "print \"data loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>update-date</th>\n",
       "      <th>industries</th>\n",
       "      <th>job-name</th>\n",
       "      <th>salary</th>\n",
       "      <th>currency</th>\n",
       "      <th>employment</th>\n",
       "      <th>schedule</th>\n",
       "      <th>description</th>\n",
       "      <th>experience</th>\n",
       "      <th>contract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174673</td>\n",
       "      <td>2015-08-18 00:31:14 GMT+4</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Бетонщик</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;В Компанию с центральным офисом в Москве (в...</td>\n",
       "      <td>1-3 года</td>\n",
       "      <td>постоянный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130222</td>\n",
       "      <td>2015-08-19 00:15:58 GMT+4</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Руководитель интернет-проекта (обувь)</td>\n",
       "      <td>от 50000 до 70000</td>\n",
       "      <td>RUR</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Должностные обязанности:&lt;/strong&gt;&lt;/...</td>\n",
       "      <td>3-6 лет</td>\n",
       "      <td>постоянный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121331</td>\n",
       "      <td>2015-08-19 01:44:02 GMT+4</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Врач-офтальмолог</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>3-6 лет</td>\n",
       "      <td>постоянный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30170</td>\n",
       "      <td>2015-08-20 11:29:29 GMT+4</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Специалист аналитического отдела</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Проектная/Временная работа</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>1-3 года</td>\n",
       "      <td>постоянный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43059</td>\n",
       "      <td>2015-08-20 11:01:03 GMT+4</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Руководитель проекта лаборатории нефтехимическ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;Руководитель проекта лаборатории нефтехимич...</td>\n",
       "      <td>1-3 года</td>\n",
       "      <td>постоянный</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                update-date industries  \\\n",
       "0  174673  2015-08-18 00:31:14 GMT+4   \\n         \n",
       "1  130222  2015-08-19 00:15:58 GMT+4   \\n         \n",
       "2  121331  2015-08-19 01:44:02 GMT+4   \\n         \n",
       "3   30170  2015-08-20 11:29:29 GMT+4   \\n         \n",
       "4   43059  2015-08-20 11:01:03 GMT+4   \\n         \n",
       "\n",
       "                                            job-name             salary  \\\n",
       "0                                           Бетонщик                NaN   \n",
       "1              Руководитель интернет-проекта (обувь)  от 50000 до 70000   \n",
       "2                                   Врач-офтальмолог                NaN   \n",
       "3                   Специалист аналитического отдела                NaN   \n",
       "4  Руководитель проекта лаборатории нефтехимическ...                NaN   \n",
       "\n",
       "  currency                  employment     schedule  \\\n",
       "0      NaN            Полная занятость  Полный день   \n",
       "1      RUR            Полная занятость  Полный день   \n",
       "2      NaN            Полная занятость  Полный день   \n",
       "3      NaN  Проектная/Временная работа  Полный день   \n",
       "4      NaN            Полная занятость  Полный день   \n",
       "\n",
       "                                         description experience    contract  \n",
       "0  <p>В Компанию с центральным офисом в Москве (в...   1-3 года  постоянный  \n",
       "1  <p><strong>Должностные обязанности:</strong></...    3-6 лет  постоянный  \n",
       "2  <p><strong>Обязанности:</strong></p> <ul> <li>...    3-6 лет  постоянный  \n",
       "3  <p><strong>Обязанности:</strong></p> <ul> <li>...   1-3 года  постоянный  \n",
       "4  <p>Руководитель проекта лаборатории нефтехимич...   1-3 года  постоянный  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print dt_train.shape\n",
    "dt_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19999\n"
     ]
    }
   ],
   "source": [
    "# joining all data\n",
    "dt_all = pd.concat((dt_train,dt_test),axis=0)\n",
    "dt_all.index = range (dt_all.shape[0])\n",
    "\n",
    "print max(dt_all.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## removing nans from y_class\n",
    "y_class [np.isnan(y_class)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_all = dt_all.drop(['industries','currency','update-date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 8)\n",
      "(20000, 2)\n"
     ]
    }
   ],
   "source": [
    "# s - string salary\n",
    "def process_salary(salary_str):\n",
    "    l_bound = np.nan\n",
    "    h_bound = np.nan\n",
    "    try:\n",
    "        m = re.search(u'от ([0-9]*)', salary_str)\n",
    "        if m: \n",
    "            l_bound = float(m.group(1))\n",
    "        m = re.search(u'до ([0-9]*)', salary_str)\n",
    "        if m: \n",
    "            h_bound = float(m.group(1))\n",
    "    except:\n",
    "        pass\n",
    "    return l_bound, h_bound  \n",
    "\n",
    "\n",
    "salary_hl = pd.DataFrame(map(process_salary, dt_all['salary']),columns=['low_sal','high_sal'])\n",
    "\n",
    "print dt_all.shape\n",
    "print salary_hl.shape\n",
    "\n",
    "dt_all = dt_all.join(salary_hl)\n",
    "dt_all = dt_all.drop('salary', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## replacing nans with approximations\n",
    "mean_rel = np.mean(dt_all['high_sal']/dt_all['low_sal'])\n",
    "\n",
    "null_rows = np.isnan(dt_all['low_sal'])\n",
    "dt_all.loc[null_rows,'low_sal'] = dt_all['high_sal'][null_rows] / mean_rel\n",
    "\n",
    "null_rows = np.isnan(dt_all['high_sal'])\n",
    "dt_all.loc[null_rows,'high_sal'] = dt_all['low_sal'][null_rows] * mean_rel\n",
    "\n",
    "\n",
    "## replacing all missing values with zeroes\n",
    "dt_all['no_sal_data'] = 0\n",
    "null_rows = np.isnan(dt_all['high_sal'])\n",
    "dt_all.loc[null_rows,'no_sal_data'] = 1\n",
    "dt_all.loc[null_rows,'low_sal'] = 0\n",
    "dt_all.loc[null_rows,'high_sal'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job-name</th>\n",
       "      <th>employment</th>\n",
       "      <th>schedule</th>\n",
       "      <th>description</th>\n",
       "      <th>experience</th>\n",
       "      <th>contract</th>\n",
       "      <th>low_sal</th>\n",
       "      <th>high_sal</th>\n",
       "      <th>no_sal_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174673</td>\n",
       "      <td>Бетонщик</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;В Компанию с центральным офисом в Москве (в...</td>\n",
       "      <td>1-3 года</td>\n",
       "      <td>постоянный</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130222</td>\n",
       "      <td>Руководитель интернет-проекта (обувь)</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Должностные обязанности:&lt;/strong&gt;&lt;/...</td>\n",
       "      <td>3-6 лет</td>\n",
       "      <td>постоянный</td>\n",
       "      <td>50000</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121331</td>\n",
       "      <td>Врач-офтальмолог</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>3-6 лет</td>\n",
       "      <td>постоянный</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30170</td>\n",
       "      <td>Специалист аналитического отдела</td>\n",
       "      <td>Проектная/Временная работа</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>1-3 года</td>\n",
       "      <td>постоянный</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43059</td>\n",
       "      <td>Руководитель проекта лаборатории нефтехимическ...</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;Руководитель проекта лаборатории нефтехимич...</td>\n",
       "      <td>1-3 года</td>\n",
       "      <td>постоянный</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           job-name  \\\n",
       "0  174673                                           Бетонщик   \n",
       "1  130222              Руководитель интернет-проекта (обувь)   \n",
       "2  121331                                   Врач-офтальмолог   \n",
       "3   30170                   Специалист аналитического отдела   \n",
       "4   43059  Руководитель проекта лаборатории нефтехимическ...   \n",
       "\n",
       "                   employment     schedule  \\\n",
       "0            Полная занятость  Полный день   \n",
       "1            Полная занятость  Полный день   \n",
       "2            Полная занятость  Полный день   \n",
       "3  Проектная/Временная работа  Полный день   \n",
       "4            Полная занятость  Полный день   \n",
       "\n",
       "                                         description experience    contract  \\\n",
       "0  <p>В Компанию с центральным офисом в Москве (в...   1-3 года  постоянный   \n",
       "1  <p><strong>Должностные обязанности:</strong></...    3-6 лет  постоянный   \n",
       "2  <p><strong>Обязанности:</strong></p> <ul> <li>...    3-6 лет  постоянный   \n",
       "3  <p><strong>Обязанности:</strong></p> <ul> <li>...   1-3 года  постоянный   \n",
       "4  <p>Руководитель проекта лаборатории нефтехимич...   1-3 года  постоянный   \n",
       "\n",
       "   low_sal  high_sal  no_sal_data  \n",
       "0        0         0            1  \n",
       "1    50000     70000            0  \n",
       "2        0         0            1  \n",
       "3        0         0            1  \n",
       "4        0         0            1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Creating one-hot features for category columns\n",
    "\n",
    "def make_bin_cols(table_data):\n",
    "   pass \n",
    "\n",
    "col_names = ['employment','schedule','experience','contract']\n",
    "dt_bin = pd.DataFrame()\n",
    "dt = dt_all[col_names]\n",
    "j = 0\n",
    "\n",
    "for j in range(dt.shape[1]):\n",
    "    for row_val in np.unique(dt.iloc[:,j]):\n",
    "        new_col = np.zeros(dt.shape[0])   \n",
    "        new_col[np.array(dt.iloc[:,j] == row_val)] = 1\n",
    "        col_name = dt.columns.values[j] + \"_\" + row_val\n",
    "        dt_bin[col_name] = new_col\n",
    "        \n",
    "dt_all = dt_all.join(dt_bin)\n",
    "dt_all = dt_all.drop(col_names, axis =1 )\n",
    "##pd.Series(np.unique(dt_all['employment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_str(mystr):\n",
    "    text = re.sub(u\"<.*?>\",\"\", mystr)\n",
    "    text = re.sub(u\"&quot;\",\"\", text)\n",
    "    return text\n",
    "    \n",
    "dt_all['description'] = map(clean_str, dt_all['description'])\n",
    "dt_all['job-name'] = map(clean_str, dt_all['job-name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##  nltk.download(\"punkt\")\n",
    "##\n",
    "##  http://www.markhneedham.com/blog/2015/02/15/pythonscikit-learn-calculating-tfidf-on-how-i-met-your-mother-transcripts/\n",
    "##\n",
    "\n",
    "def tokenize(text):\n",
    "    stemmer = SnowballStemmer(\"russian\")\n",
    "    text = re.sub(u\"[^a-zA-Z0-9а-яА-Я -]\",\"\",text)\n",
    "    text = re.sub(u\"--\",\"\",text) \n",
    "    text = re.sub(u\"($-)|( -)|(-^)\",\"\",text)\n",
    "    text = re.sub(u\" 000\",u\"000\",text)\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = []\n",
    "    \n",
    "    for item in tokens:\n",
    "        stems.append(stemmer.stem(item))\n",
    "    return stems\n",
    "\n",
    "\n",
    "def make_tfidf_decomposition (train_dt, test_dt, pca_size, tokenizer_func, ngram_range=(1, 5)):\n",
    "\n",
    "    rus_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "    tfidf = TfidfVectorizer(tokenizer=tokenizer_func, ngram_range=ngram_range, min_df=15, stop_words = rus_stopwords)\n",
    "\n",
    "    tfs_train = tfidf.fit_transform(train_dt)\n",
    "    tfs_test  = tfidf.transform(test_dt)\n",
    "\n",
    "    pca_tf = PCA(n_components = pca_size)\n",
    "    ## pca_tf = TSNE(n_components = pca_size)\n",
    "\n",
    "    tfs_train = pd.DataFrame(pca_tf.fit_transform (tfs_train.todense()))\n",
    "    tfs_test  = pd.DataFrame(pca_tf.transform (tfs_test.todense()))\n",
    "    \n",
    "    feature_names = pd.Series(tfidf.get_feature_names())\n",
    "\n",
    "    return tfs_train, tfs_test, feature_names\n",
    "\n",
    "# pd.set_option('display.max_rows', 1000)\n",
    "# print feature_names\n",
    "# pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 20)\n",
      "(20000, 200) (20000, 220)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirorezka/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/utils/extmath.py:360: UserWarning: The number of power iterations is increased to 7 to achieve higher precision.\n",
      "  warnings.warn(\"The number of power iterations is increased to 7 to \"\n"
     ]
    }
   ],
   "source": [
    "## Create TFIDF vectors from description data\n",
    "##\n",
    "\n",
    "n_shape = dt_all.shape[0]/2\n",
    "n_shape\n",
    "descr_train, descr_test, feat_name = make_tfidf_decomposition (dt_all['description'][0:n_shape], dt_all['description'][n_shape:], pca_size = 200, tokenizer_func = tokenize)\n",
    "\n",
    "descr_train.columns = map (lambda x: 'descr ' + (str(x)), descr_train.columns.values)\n",
    "descr_test.columns  = map (lambda x: 'descr ' + (str(x)), descr_test.columns.values)\n",
    "\n",
    "descr_all = pd.concat((descr_train,descr_test),axis=0)\n",
    "descr_all.index = range(descr_all.shape[0])\n",
    "\n",
    "print dt_all.shape\n",
    "dt_all = dt_all.join(descr_all)\n",
    "print descr_all.shape, dt_all.shape\n",
    "\n",
    "## del descr_train, descr_test, descr_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 220)\n",
      "(20000, 250)\n"
     ]
    }
   ],
   "source": [
    "## Create TFIDF vectors from job-name data\n",
    "##\n",
    "\n",
    "n_shape = dt_all.shape[0]/2\n",
    "\n",
    "title_train, title_test, feat_name = make_tfidf_decomposition (dt_all['job-name'][0:n_shape], dt_all['job-name'][n_shape:], pca_size = 30, tokenizer_func = tokenize)\n",
    "\n",
    "title_train.columns = map (lambda x: 'title ' + (str(x)), title_train.columns.values)\n",
    "title_test.columns  = map (lambda x: 'title ' + (str(x)), title_test.columns.values)\n",
    "\n",
    "title_all = pd.concat((title_train, title_test),axis=0)\n",
    "title_all.index = range(title_all.shape[0])\n",
    "\n",
    "print dt_all.shape\n",
    "dt_all = dt_all.join(title_all)\n",
    "print dt_all.shape\n",
    "\n",
    "del title_train, title_test, title_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed:  2.48710298538\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## tokenize information to gather type of education required by employee\n",
    "##\n",
    "\n",
    "import time\n",
    "\n",
    "def get_educ_text(text_string):\n",
    "    text = re.sub(u\"[,+;'/:`()]\",\" \", text_string.lower())\n",
    "    text = re.sub(u\"[-]\",\" \",text)\n",
    "    \n",
    "    ## gr1 = re.finditer(u'([а-яa-z]*[ ]{0,3}){0,5} образование',text.lower())\n",
    "    gr1 = re.finditer (u'[а-яa-z]*[ ]{0,1} [а-яa-z]*[ ]{0,1} [а-яa-z]* образование',text)\n",
    "    gr2 = re.finditer(u'образование ([а-яa-z]*[ ]{0,3}){0,5}',text.lower())\n",
    "    educ_spec = \"\"\n",
    "    try:\n",
    "        for k in gr1:\n",
    "            educ_spec = educ_spec + \" \" + k.group(0)\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        for k in gr2:\n",
    "            educ_spec = educ_spec + \" \" + k.group(0)\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "    return educ_spec\n",
    "\n",
    " \n",
    "\n",
    "tic = time.time()\n",
    "pool = Pool(processes = N_PROCS)\n",
    "tt = pool.map(get_educ_text, dt_all['description'])\n",
    "pool.close()\n",
    "pool.join()\n",
    "toc = time.time()\n",
    "\n",
    "print \"Time passed: \", toc - tic\n",
    "\n",
    "## pd.set_option('max_colwidth',100)\n",
    "## print pd.Series(tt)\n",
    "\n",
    "dt_all['educ_text'] = tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "n_shape = dt_all.shape[0]/2\n",
    "educ_train, educ_test, feat_name = make_tfidf_decomposition (dt_all['educ_text'][0:n_shape], dt_all['educ_text'][n_shape:], \n",
    "                                                             pca_size = 30, tokenizer_func = tokenize, ngram_range=(1, 2))\n",
    "\n",
    "educ_train.columns = map (lambda x: 'educ ' + (str(x)), educ_train.columns.values)\n",
    "educ_test.columns  = map (lambda x: 'educ ' + (str(x)), educ_test.columns.values)\n",
    "\n",
    "educ_all = pd.concat((educ_train, educ_test),axis=0)\n",
    "educ_all.index = range(educ_all.shape[0])\n",
    "\n",
    "print dt_all.shape[1]\n",
    "dt_all = dt_all.join(educ_all)\n",
    "print dt_all.shape[1]\n",
    "\n",
    "del educ_train, educ_test, educ_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed:  0.540234088898\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "###  Collect previous working experience in job description\n",
    "###\n",
    "\n",
    "import time\n",
    "\n",
    "def get_prev_experience(text_string):\n",
    "    text = re.sub(u\"[,+;'/:`()]\",\" \", text_string.lower())\n",
    "    text = re.sub(u\"[-]\",\" \",text)\n",
    "    \n",
    "    gr = re.finditer(u'опыт ([а-яa-z0-9]*[ ]{0,3}){0,5}',text.lower())\n",
    "    educ_spec = \"\"\n",
    "    try:\n",
    "        for k in gr:\n",
    "            educ_spec = educ_spec + \" \" + k.group(0)\n",
    "    except: \n",
    "        pass\n",
    "    return educ_spec\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "## processing xml data in pool\n",
    "pool = Pool(processes = N_PROCS)\n",
    "tt = pool.map(get_prev_experience, dt_all['description'])\n",
    "pool.close()\n",
    "pool.join()\n",
    "##\n",
    "toc = time.time()\n",
    "\n",
    "print \"Time passed: \", toc - tic\n",
    "\n",
    "dt_all['experience_text'] = tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n",
      "332\n"
     ]
    }
   ],
   "source": [
    "n_shape = dt_all.shape[0]/2\n",
    "exp_train, exp_test, feat_name = make_tfidf_decomposition (dt_all['experience_text'][0:n_shape], dt_all['experience_text'][n_shape:], \n",
    "                                                             pca_size = 50, tokenizer_func = tokenize, ngram_range=(1, 3))\n",
    "\n",
    "exp_train.columns = map (lambda x: 'experience ' + (str(x)), exp_train.columns.values)\n",
    "exp_test.columns  = map (lambda x: 'experience ' + (str(x)), exp_test.columns.values)\n",
    "\n",
    "exp_all = pd.concat((exp_train, exp_test),axis=0)\n",
    "exp_all.index = range(exp_all.shape[0])\n",
    "\n",
    "print dt_all.shape[1]\n",
    "dt_all = dt_all.join(exp_all)\n",
    "print dt_all.shape[1]\n",
    "\n",
    "del exp_train, exp_test, exp_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read education dictionary\n"
     ]
    }
   ],
   "source": [
    "## Loking for type of the education\n",
    "\n",
    "educt_words = pd.read_csv('educ_dictionary.txt', encoding = \"utf-8\")\n",
    "educt_words = educt_words.iloc[:,0].tolist()\n",
    "print \"Read education dictionary\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industries tokenized\n"
     ]
    }
   ],
   "source": [
    "## Generating list of words from job names\n",
    "##\n",
    "\n",
    "prof_words = []\n",
    "\n",
    "for w in pd.Series(y_class.columns.values):\n",
    "    prof_words = prof_words + tokenize(w)\n",
    "    ##print pd.Series(tokenize(w))\n",
    "\n",
    "print \"Industries tokenized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special words added\n"
     ]
    }
   ],
   "source": [
    "## generate bool index columns with special words:\n",
    "\n",
    "special_words = [u\"руковод\",u\"медиа\",u\"маркетин\",u\"автомоб\",u\"машин\",u\"юрист\",u\"бухгалт\",u\"страхова\",u\"менедж\",u\"продаж\",u\"реклам\"]\n",
    "special_words = special_words + [u'инженер',u'анлгийск',u'english',u'лаборат',u'исследов',u'медицин',u'программ',u'риск',u'финанс']\n",
    "special_words = special_words + [u'закуп',u'снабжен',u'кассир',u'дизайнер',u'архитектур',u'строитель',u'туризм',u'логист']\n",
    "special_words = special_words + [u'страхов',u'аналит']\n",
    "\n",
    "progs = [u\"1с бухгалтерия\",u\"office\",u\"MS office\",u\"excel\",u\"word\",u\"outlook\",u'autocad',u'Adobe Illustrator',u'VBA',u'SQL']\n",
    "progs = progs + [u'Photoshop', u'Corel Draw', u'PHP', u'КАСКО', u'ОСАГО', u'ДГО']\n",
    "\n",
    "special_words = special_words + progs + prof_words + educt_words\n",
    "special_words = np.unique(pd.Series(special_words))\n",
    "\n",
    "\n",
    "for i_word in special_words:\n",
    "    new_col = np.zeros(dt_all.shape[0])\n",
    "    tt = map (lambda x: re.search(i_word.lower(), x.lower())==None, dt_all['job-name'])\n",
    "    tt = ~np.array(tt)\n",
    "    new_col[tt] = 1\n",
    "    col_name = \"job-name \" + i_word\n",
    "    dt_all[col_name] = new_col\n",
    "    \n",
    "    new_col = np.zeros(dt_all.shape[0])\n",
    "    tt = map (lambda x: re.search(i_word.lower(), x.lower())==None, dt_all['description'])\n",
    "    tt = ~np.array(tt)\n",
    "    new_col[tt] = 1\n",
    "    col_name = \"description \" + i_word.lower()\n",
    "    dt_all[col_name] = new_col    \n",
    "\n",
    "print \"Special words added\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584\n",
      "584\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job-name</th>\n",
       "      <th>description</th>\n",
       "      <th>low_sal</th>\n",
       "      <th>high_sal</th>\n",
       "      <th>no_sal_data</th>\n",
       "      <th>employment_Полная занятость</th>\n",
       "      <th>employment_Проектная/Временная работа</th>\n",
       "      <th>employment_Стажировка</th>\n",
       "      <th>employment_Частичная занятость</th>\n",
       "      <th>...</th>\n",
       "      <th>job-name экономи</th>\n",
       "      <th>description экономи</th>\n",
       "      <th>job-name электротехнич</th>\n",
       "      <th>description электротехнич</th>\n",
       "      <th>job-name юридическ</th>\n",
       "      <th>description юридическ</th>\n",
       "      <th>job-name юриспруден</th>\n",
       "      <th>description юриспруден</th>\n",
       "      <th>job-name юрист</th>\n",
       "      <th>description юрист</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174673</td>\n",
       "      <td>Бетонщик</td>\n",
       "      <td>В Компанию с центральным офисом в Москве (вход...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130222</td>\n",
       "      <td>Руководитель интернет-проекта (обувь)</td>\n",
       "      <td>Должностные обязанности:  Управление ИНТЕРНЕТ ...</td>\n",
       "      <td>50000</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121331</td>\n",
       "      <td>Врач-офтальмолог</td>\n",
       "      <td>Обязанности:  проведение полной диагностики со...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30170</td>\n",
       "      <td>Специалист аналитического отдела</td>\n",
       "      <td>Обязанности:  Обработка больших массивов инфор...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43059</td>\n",
       "      <td>Руководитель проекта лаборатории нефтехимическ...</td>\n",
       "      <td>Руководитель проекта лаборатории нефтехимическ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 584 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           job-name  \\\n",
       "0  174673                                           Бетонщик   \n",
       "1  130222              Руководитель интернет-проекта (обувь)   \n",
       "2  121331                                   Врач-офтальмолог   \n",
       "3   30170                   Специалист аналитического отдела   \n",
       "4   43059  Руководитель проекта лаборатории нефтехимическ...   \n",
       "\n",
       "                                         description  low_sal  high_sal  \\\n",
       "0  В Компанию с центральным офисом в Москве (вход...        0         0   \n",
       "1  Должностные обязанности:  Управление ИНТЕРНЕТ ...    50000     70000   \n",
       "2  Обязанности:  проведение полной диагностики со...        0         0   \n",
       "3  Обязанности:  Обработка больших массивов инфор...        0         0   \n",
       "4  Руководитель проекта лаборатории нефтехимическ...        0         0   \n",
       "\n",
       "   no_sal_data  employment_Полная занятость  \\\n",
       "0            1                            1   \n",
       "1            0                            1   \n",
       "2            1                            1   \n",
       "3            1                            0   \n",
       "4            1                            1   \n",
       "\n",
       "   employment_Проектная/Временная работа  employment_Стажировка  \\\n",
       "0                                      0                      0   \n",
       "1                                      0                      0   \n",
       "2                                      0                      0   \n",
       "3                                      1                      0   \n",
       "4                                      0                      0   \n",
       "\n",
       "   employment_Частичная занятость        ...          job-name экономи  \\\n",
       "0                               0        ...                         0   \n",
       "1                               0        ...                         0   \n",
       "2                               0        ...                         0   \n",
       "3                               0        ...                         0   \n",
       "4                               0        ...                         0   \n",
       "\n",
       "   description экономи  job-name электротехнич  description электротехнич  \\\n",
       "0                    0                       0                          0   \n",
       "1                    0                       0                          0   \n",
       "2                    0                       0                          0   \n",
       "3                    0                       0                          0   \n",
       "4                    0                       0                          0   \n",
       "\n",
       "   job-name юридическ  description юридическ  job-name юриспруден  \\\n",
       "0                   0                      0                    0   \n",
       "1                   0                      0                    0   \n",
       "2                   0                      0                    0   \n",
       "3                   0                      0                    0   \n",
       "4                   0                      0                    0   \n",
       "\n",
       "   description юриспруден  job-name юрист  description юрист  \n",
       "0                       0               0                  0  \n",
       "1                       0               0                  0  \n",
       "2                       0               0                  0  \n",
       "3                       0               0                  0  \n",
       "4                       0               0                  0  \n",
       "\n",
       "[5 rows x 584 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(dt_all.columns.values)\n",
    "print len(np.unique(dt_all.columns.values))\n",
    "\n",
    "dt_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584\n",
      "561\n"
     ]
    }
   ],
   "source": [
    "## Remove constant columns\n",
    "##\n",
    "\n",
    "col_remove = []\n",
    "\n",
    "for i in range(dt_all.shape[1]):\n",
    "    same_cols = np.sum(dt_all.iloc[:,i] == dt_all.iloc[0,i]) \n",
    "    if same_cols == dt_all.shape[0]:\n",
    "        col_remove.append(dt_all.columns.values[i])\n",
    "    \n",
    "print dt_all.shape[1]\n",
    "dt_all = dt_all.drop(col_remove,axis=1)\n",
    "print dt_all.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 561)\n",
      "(20000, 561)\n"
     ]
    }
   ],
   "source": [
    "X = dt_all.copy(deep = True)\n",
    "print X.shape\n",
    "print dt_all.shape\n",
    "\n",
    "ids = dt_all['id']\n",
    "X = X.drop(['id','job-name','description'], axis = 1)\n",
    "\n",
    "try:\n",
    "    X = X.drop(['educ_text'], axis = 1)\n",
    "    X = X.drop(['experience_text'], axis = 1)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Автомобильный бизнес                                      289\n",
       "Административный персонал                                 613\n",
       "Банки, инвестиции, лизинг                                1081\n",
       "Безопасность                                              199\n",
       "Бухгалтерия, управленческий учет, финансы предприятия     946\n",
       "Высший менеджмент                                         448\n",
       "Государственная служба, некоммерческие организации         25\n",
       "Добыча сырья                                              215\n",
       "Домашний персонал                                         102\n",
       "Закупки                                                   219\n",
       "Инсталляция и сервис                                      174\n",
       "Информационные технологии, интернет, телеком             1380\n",
       "Искусство, развлечения, масс-медиа                        200\n",
       "Консультирование                                          260\n",
       "Маркетинг, реклама, PR                                   1344\n",
       "Медицина, фармацевтика                                    472\n",
       "Наука, образование                                        181\n",
       "Продажи                                                  4280\n",
       "Производство                                             1181\n",
       "Рабочий персонал                                         1210\n",
       "Спортивные клубы, фитнес, салоны красоты                  113\n",
       "Страхование                                               340\n",
       "Строительство, недвижимость                              1211\n",
       "Транспорт, логистика                                      833\n",
       "Туризм, гостиницы, рестораны                              416\n",
       "Управление персоналом, тренинги                           332\n",
       "Юристы                                                    138\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_class == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Changing values in y_class to class numbers and lists\n",
    "## i.e. from [0,1,0,1,0,0,1 ... ] to [2,4,7,..]\n",
    "##\n",
    "\n",
    "def makePredictionList(Ypred):\n",
    "    Ypred = np.vstack(Ypred)\n",
    "    Ypred = np.transpose(Ypred)\n",
    "    Ypred = map (lambda tt: Ypred[tt,Ypred[tt,:]!=0].astype(int).tolist(), range(Ypred.shape[0])) \n",
    "    return Ypred\n",
    "\n",
    "\n",
    "y_class_vals = pd.DataFrame(index=range(y_class.shape[0]))\n",
    "Ytrue = []\n",
    "\n",
    "for i_col in range(y_class.shape[1]):\n",
    "    col_name = y_class.columns.values[i_col]\n",
    "    new_col = np.zeros(y_class.shape[0])\n",
    "    new_col[np.array(y_class.loc[:,col_name]==1)] = i_col + 1\n",
    "    Ytrue.append(new_col)\n",
    "\n",
    "Ytrue = makePredictionList (Ytrue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3000\n",
      "2 5923\n",
      "3 975\n",
      "4 85\n",
      "5 11\n",
      "6 6\n"
     ]
    }
   ],
   "source": [
    "## Count number of categories for each id\n",
    "##\n",
    "\n",
    "num_cat_list = map (lambda tt: len(Ytrue[tt]), range(len(Ytrue)))\n",
    "\n",
    "for k in np.unique(num_cat_list):\n",
    "    print k, sum(num_cat_list==k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "## sorting probas and return top_2\n",
    "def getTopClassByProba (prob_list, top_num):\n",
    "    \n",
    "    tt = prob_list\n",
    "    tt = zip(np.arange(1,len(tt)+1),tt)\n",
    "    top_2 = sorted(tt,key=operator.itemgetter(1),reverse=True)[0:top_num]\n",
    "    top_2 = pd.DataFrame(top_2)[0].tolist()\n",
    "    return top_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## based on Yprob matrix and ytrue real classes return threshold to maximize f1 statistic\n",
    "##\n",
    "\n",
    "def getBestProbVals(Yproba, y_true):\n",
    "    num_class = y_true.shape[1]\n",
    "\n",
    "    prob_arr = np.zeros(num_class)\n",
    "    fmax_arr = np.zeros(num_class)\n",
    "\n",
    "    for t_cat in range(num_class):\n",
    "        Ytrainproba = pd.DataFrame(Yproba)\n",
    "        col_prob = Yproba.iloc[:,t_cat]\n",
    "        fmax = 0\n",
    "        prob_best = 0\n",
    "        for p_prob in np.arange(0,1,0.01):\n",
    "            col_class = np.array(col_prob>p_prob).astype(int)\n",
    "            col_f1_score = f1_score(y_true.iloc[:,t_cat], col_class)\n",
    "            if col_f1_score > fmax:\n",
    "                prob_best = p_prob\n",
    "                fmax = col_f1_score\n",
    "            ## print p_prob, col_f1_score\n",
    "\n",
    "        ## print prob_best, fmax\n",
    "        prob_arr[t_cat] = prob_best\n",
    "        fmax_arr[t_cat] = fmax\n",
    "\n",
    "    return prob_arr, fmax_arr \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert predicted probas (y_prob) to classes if they are greater then predefined values in prob_arr \n",
    "##\n",
    "\n",
    "def probasToClasses(y_prob, prob_arr):\n",
    "    class_filt = y_prob>prob_arr\n",
    "    classes = np.arange(1,len(y_prob)+1)[class_filt].tolist()\n",
    "    return classes\n",
    "\n",
    "\n",
    "##map (lambda x: probasToClasses(Yproba[x,],prob_arr) ,range(Yproba.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###  Making data classification:\n",
    "###\n",
    "###  1. doing standard xgboost classification on each class separately\n",
    "###  2. Using class probas to estimate effective probability threshold for each class.\n",
    "###  3. Estimating classes from threshold\n",
    "###  4. If set of classes is empty for eany id then best two classes are used\n",
    "###\n",
    "\n",
    "\n",
    "Ypred  = []\n",
    "Yproba = []\n",
    "Ytrainproba = []\n",
    "\n",
    "\n",
    "train_test_split = StratifiedShuffleSplit(y_class.iloc[:,0], n_iter = 1, test_size = 0.3)\n",
    "\n",
    "for train_index, test_index in train_test_split:\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    y_train_all, y_test_all = y_class.iloc[train_index,:], y_class.iloc[test_index,:]\n",
    "    \n",
    "    \n",
    "    for t_cat in  range(y_class.shape[1]):\n",
    "\n",
    "        y_train, y_test = y_train_all.iloc[:,t_cat], y_test_all.iloc[:,t_cat]\n",
    "        \n",
    "        \n",
    "        # feature selection\n",
    "        clf = ExtraTreesClassifier (n_estimators= 300, min_samples_leaf=5)\n",
    "        clf.fit(X_train,y_train)     \n",
    "        feat_imp = zip (np.arange(1,X_train.shape[1]),clf.feature_importances_)\n",
    "        k = 250\n",
    "        top_k = sorted(feat_imp,key=operator.itemgetter(1),reverse=True)[0:k]\n",
    "        top_k = pd.DataFrame(top_k)[0].tolist() \n",
    "        ## print top_k\n",
    "        \n",
    "        \n",
    "        #clf = RandomForestClassifier (n_estimators= 200, min_samples_leaf=5, n_jobs = -1)\n",
    "        clf = xgb.XGBClassifier(missing=np.nan, max_depth=5, n_estimators=310, \n",
    "                                learning_rate=0.03, nthread=8, subsample=0.95, colsample_bytree=0.85, seed=4242)\n",
    "        \n",
    "\n",
    "        clf.fit(X_train.iloc[:,top_k],y_train)    \n",
    "        y_train_proba = clf.predict_proba(X_train.iloc[:,top_k])\n",
    "        \n",
    "        y_proba = clf.predict_proba(X_test.iloc[:,top_k])\n",
    "        y_pred = y_proba[:,1]>0.2\n",
    "        y_pred = y_pred.astype(int)\n",
    "        y_pred [y_pred==1] = t_cat+1\n",
    "        \n",
    "        Ypred.append(y_pred)\n",
    "        Yproba.append(y_proba[:,1])\n",
    "        Ytrainproba.append(y_train_proba[:,1])\n",
    "    \n",
    "    Yproba = np.vstack(Yproba)\n",
    "    Yproba = np.transpose(Yproba)\n",
    "    \n",
    "    Ytrainproba = np.vstack(Ytrainproba)\n",
    "    Ytrainproba = np.transpose(Ytrainproba)\n",
    "    Ytrainproba = pd.DataFrame(Ytrainproba)\n",
    "    \n",
    "    prob_arr, fmax_arr = getBestProbVals(Ytrainproba, y_train_all)\n",
    "    Ypred = map (lambda x: probasToClasses(Yproba[x,],prob_arr) ,range(Yproba.shape[0]))\n",
    "    \n",
    "    # replace null answers with top 2\n",
    "    for k in range(len(Ypred)):\n",
    "        if len(Ypred[k]) == 0:\n",
    "            Ypred[k] = getTopClassByProba (Yproba[k,:], 2)\n",
    "    \n",
    "    \n",
    "    ## Ypred = map (lambda x: getTopClassByProba(Yproba[x,:], 2),range(Yproba.shape[0]))\n",
    "\n",
    "    Ytrue_test = np.array(Ytrue)[test_index].tolist()\n",
    "\n",
    "    print mean_f1 (Ytrue_test,Ypred)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78594004329\n"
     ]
    }
   ],
   "source": [
    "Ypred  = []\n",
    "\n",
    "for t_cat in  range(y_class.shape[1]):\n",
    "    \n",
    "    y_train, y_test = y_train_all.iloc[:,t_cat], y_test_all.iloc[:,t_cat]\n",
    "    \n",
    "    clf = RandomForestClassifier (n_estimators= 200, min_samples_leaf=5, n_jobs = -1)\n",
    "    clf.fit (Ytrainproba, y_train)\n",
    "    y_pred = clf.predict(Yproba)\n",
    "    y_pred [y_pred==1] = t_cat+1\n",
    "    Ypred.append(y_pred)\n",
    "    Ynew_proba = clf.predict_proba(Yproba)\n",
    "    \n",
    "\n",
    "Ypred = makePredictionList(Ypred)\n",
    "\n",
    "Ynew_proba = np.vstack(Ynew_proba)\n",
    "Ynew_proba = np.transpose(Ynew_proba)\n",
    "\n",
    "for k in range(len(Ypred)):\n",
    "    if len(Ypred[k]) == 0:\n",
    "        Ypred[k] = getTopClassByProba (Yproba[k,:], 2)\n",
    "        \n",
    "print mean_f1 (Ytrue_test,Ypred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print len(Ytrue_test)\n",
    "print len(Ypred)\n",
    "\n",
    "# print zip(np.arange(1,len(Yproba[i])),prob_arr)\n",
    "# print probasToClasses(Yproba[0,:],prob_arr)\n",
    "print \"\"\n",
    "\n",
    "for i in range(20):\n",
    "    print Ytrue_test[i],Ypred[i],zip(np.arange(1,len(Yproba[i])),Yproba[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 193\n",
    "print Ytrue_test[i],Ypred[i],zip(np.arange(1,len(Yproba[i])+1),Yproba[i])\n",
    "test_index[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dt_all.loc[test_index[i],\"job-name\"]\n",
    "print dt_all.loc[test_index[i],\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_class.iloc[test_index[i],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dt_all.loc[test_index[i],\"description\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_all['educ_text'].to_csv('educ_text.csv', encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
