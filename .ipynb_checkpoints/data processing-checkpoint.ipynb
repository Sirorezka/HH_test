{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sirorezka/anaconda2/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.py:43: DeprecationWarning: This module has been deprecated in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from mean_f1 import *  ## library with mean_f1 metric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import xgboost as xgb\n",
    " \n",
    "\n",
    "from lxml import etree\n",
    "from lxml import objectify\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "N_PROCS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "##   Reading XML data\n",
    "\n",
    "def parse_tree_struct((xml_root, k)):\n",
    "\n",
    "    dt_row = dict()   ## for storing rows\n",
    "    dt_industr =  dict()  ## for storing industries\n",
    "    \n",
    "    b_childs = etree.fromstring(xml_root)\n",
    "    dt_row['id'] = b_childs.get(\"id\")\n",
    "    b_childs = b_childs.getchildren()\n",
    "    \n",
    "\n",
    "    for tree_elem in b_childs:\n",
    "        tag_val = tree_elem.tag\n",
    "        num_val = tree_elem.text\n",
    "        dt_row[tag_val] = num_val\n",
    "\n",
    "        if tree_elem.tag == 'term':\n",
    "            new_tag = tree_elem.getchildren()[0].tag\n",
    "            dt_row[new_tag] = tree_elem.getchildren()[0].text\n",
    "\n",
    "        if tree_elem.tag == 'requirement':\n",
    "            new_tag = tree_elem.getchildren()[0].tag\n",
    "            dt_row[new_tag] = tree_elem.getchildren()[0].text\n",
    "\n",
    "        if tree_elem.tag == 'industries':\n",
    "            for ind_elem in tree_elem.getchildren():\n",
    "                dt_industr [ind_elem.text] = 1\n",
    "\n",
    "    dt_row = pd.Series(dt_row)\n",
    "    dt_row['y_industr'] = dt_industr\n",
    "    \n",
    "    return dt_row \n",
    "\n",
    "def read_data_gz(filename_str):\n",
    "    \n",
    "    # initiate parser\n",
    "    parser = etree.XMLParser(ns_clean=True, encoding='utf-8')\n",
    "    data_train_tree = etree.parse(filename_str,parser)\n",
    "\n",
    "    # set up column names\n",
    "    col_names = ['id','update-date','industries','job-name','salary','currency','employment','schedule','description','experience','contract','y_industr']\n",
    "\n",
    "    root = data_train_tree.getroot().getchildren() ##[0:1000] ## generate sample   \n",
    "    root_data_size = len(root)\n",
    "    \n",
    "    ## processing xml data in pool\n",
    "    pool = Pool(processes = N_PROCS)\n",
    "    dt_data = pool.map(parse_tree_struct, zip(map (etree.tostring, root),\n",
    "                                                    np.array(range(root_data_size))))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "        \n",
    "    dt_data = pd.DataFrame(dt_data,columns=col_names)    \n",
    "    tt = map (lambda x: pd.Series(dict(x)), dt_data['y_industr'])\n",
    "    y_train = pd.DataFrame(tt)\n",
    "    \n",
    "    dt_data = dt_data.drop('y_industr',axis = 1)\n",
    "    ## dt_train = dt_train.append(dt_row, ignore_index=True)\n",
    "    ## y_train = y_train.append(dt_industr, ignore_index=True)\n",
    "        \n",
    "    return dt_data, y_train ##dt_train, y_train\n",
    "    \n",
    "dt_train, y_class = read_data_gz (\"Data/train.xml.gz\")\n",
    "dt_test, y_test = read_data_gz (\"Data/test.xml.gz\")\n",
    "\n",
    "print \"data loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>update-date</th>\n",
       "      <th>industries</th>\n",
       "      <th>job-name</th>\n",
       "      <th>salary</th>\n",
       "      <th>currency</th>\n",
       "      <th>employment</th>\n",
       "      <th>schedule</th>\n",
       "      <th>description</th>\n",
       "      <th>experience</th>\n",
       "      <th>contract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174673</td>\n",
       "      <td>2015-08-18 00:31:14 GMT+4</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Бетонщик</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;В Компанию с центральным офисом в Москве (в...</td>\n",
       "      <td>1-3 года</td>\n",
       "      <td>постоянный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130222</td>\n",
       "      <td>2015-08-19 00:15:58 GMT+4</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Руководитель интернет-проекта (обувь)</td>\n",
       "      <td>от 50000 до 70000</td>\n",
       "      <td>RUR</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Должностные обязанности:&lt;/strong&gt;&lt;/...</td>\n",
       "      <td>3-6 лет</td>\n",
       "      <td>постоянный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121331</td>\n",
       "      <td>2015-08-19 01:44:02 GMT+4</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Врач-офтальмолог</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>3-6 лет</td>\n",
       "      <td>постоянный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30170</td>\n",
       "      <td>2015-08-20 11:29:29 GMT+4</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Специалист аналитического отдела</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Проектная/Временная работа</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>1-3 года</td>\n",
       "      <td>постоянный</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43059</td>\n",
       "      <td>2015-08-20 11:01:03 GMT+4</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Руководитель проекта лаборатории нефтехимическ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;Руководитель проекта лаборатории нефтехимич...</td>\n",
       "      <td>1-3 года</td>\n",
       "      <td>постоянный</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                update-date industries  \\\n",
       "0  174673  2015-08-18 00:31:14 GMT+4   \\n         \n",
       "1  130222  2015-08-19 00:15:58 GMT+4   \\n         \n",
       "2  121331  2015-08-19 01:44:02 GMT+4   \\n         \n",
       "3   30170  2015-08-20 11:29:29 GMT+4   \\n         \n",
       "4   43059  2015-08-20 11:01:03 GMT+4   \\n         \n",
       "\n",
       "                                            job-name             salary  \\\n",
       "0                                           Бетонщик                NaN   \n",
       "1              Руководитель интернет-проекта (обувь)  от 50000 до 70000   \n",
       "2                                   Врач-офтальмолог                NaN   \n",
       "3                   Специалист аналитического отдела                NaN   \n",
       "4  Руководитель проекта лаборатории нефтехимическ...                NaN   \n",
       "\n",
       "  currency                  employment     schedule  \\\n",
       "0      NaN            Полная занятость  Полный день   \n",
       "1      RUR            Полная занятость  Полный день   \n",
       "2      NaN            Полная занятость  Полный день   \n",
       "3      NaN  Проектная/Временная работа  Полный день   \n",
       "4      NaN            Полная занятость  Полный день   \n",
       "\n",
       "                                         description experience    contract  \n",
       "0  <p>В Компанию с центральным офисом в Москве (в...   1-3 года  постоянный  \n",
       "1  <p><strong>Должностные обязанности:</strong></...    3-6 лет  постоянный  \n",
       "2  <p><strong>Обязанности:</strong></p> <ul> <li>...    3-6 лет  постоянный  \n",
       "3  <p><strong>Обязанности:</strong></p> <ul> <li>...   1-3 года  постоянный  \n",
       "4  <p>Руководитель проекта лаборатории нефтехимич...   1-3 года  постоянный  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print dt_train.shape\n",
    "dt_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19999\n"
     ]
    }
   ],
   "source": [
    "# joining all data\n",
    "dt_all = pd.concat((dt_train,dt_test),axis=0)\n",
    "dt_all.index = range (dt_all.shape[0])\n",
    "\n",
    "print max(dt_all.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## removing nans from y_class\n",
    "y_class [np.isnan(y_class)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_all = dt_all.drop(['industries','currency','update-date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 8)\n",
      "(20000, 2)\n"
     ]
    }
   ],
   "source": [
    "# s - string salary\n",
    "def process_salary(salary_str):\n",
    "    l_bound = np.nan\n",
    "    h_bound = np.nan\n",
    "    try:\n",
    "        m = re.search(u'от ([0-9]*)', salary_str)\n",
    "        if m: \n",
    "            l_bound = float(m.group(1))\n",
    "        m = re.search(u'до ([0-9]*)', salary_str)\n",
    "        if m: \n",
    "            h_bound = float(m.group(1))\n",
    "    except:\n",
    "        pass\n",
    "    return l_bound, h_bound  \n",
    "\n",
    "\n",
    "salary_hl = pd.DataFrame(map(process_salary, dt_all['salary']),columns=['low_sal','high_sal'])\n",
    "\n",
    "print dt_all.shape\n",
    "print salary_hl.shape\n",
    "\n",
    "dt_all = dt_all.join(salary_hl)\n",
    "dt_all = dt_all.drop('salary', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## replacing nans with approximations\n",
    "mean_rel = np.mean(dt_all['high_sal']/dt_all['low_sal'])\n",
    "\n",
    "null_rows = np.isnan(dt_all['low_sal'])\n",
    "dt_all.loc[null_rows,'low_sal'] = dt_all['high_sal'][null_rows] / mean_rel\n",
    "\n",
    "null_rows = np.isnan(dt_all['high_sal'])\n",
    "dt_all.loc[null_rows,'high_sal'] = dt_all['low_sal'][null_rows] * mean_rel\n",
    "\n",
    "\n",
    "## replacing all missing values with zeroes\n",
    "dt_all['no_sal_data'] = 0\n",
    "null_rows = np.isnan(dt_all['high_sal'])\n",
    "dt_all.loc[null_rows,'no_sal_data'] = 1\n",
    "dt_all.loc[null_rows,'low_sal'] = 0\n",
    "dt_all.loc[null_rows,'high_sal'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job-name</th>\n",
       "      <th>employment</th>\n",
       "      <th>schedule</th>\n",
       "      <th>description</th>\n",
       "      <th>experience</th>\n",
       "      <th>contract</th>\n",
       "      <th>low_sal</th>\n",
       "      <th>high_sal</th>\n",
       "      <th>no_sal_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174673</td>\n",
       "      <td>Бетонщик</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;В Компанию с центральным офисом в Москве (в...</td>\n",
       "      <td>1-3 года</td>\n",
       "      <td>постоянный</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130222</td>\n",
       "      <td>Руководитель интернет-проекта (обувь)</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Должностные обязанности:&lt;/strong&gt;&lt;/...</td>\n",
       "      <td>3-6 лет</td>\n",
       "      <td>постоянный</td>\n",
       "      <td>50000</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>121331</td>\n",
       "      <td>Врач-офтальмолог</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>3-6 лет</td>\n",
       "      <td>постоянный</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30170</td>\n",
       "      <td>Специалист аналитического отдела</td>\n",
       "      <td>Проектная/Временная работа</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>1-3 года</td>\n",
       "      <td>постоянный</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43059</td>\n",
       "      <td>Руководитель проекта лаборатории нефтехимическ...</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>&lt;p&gt;Руководитель проекта лаборатории нефтехимич...</td>\n",
       "      <td>1-3 года</td>\n",
       "      <td>постоянный</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                           job-name  \\\n",
       "0  174673                                           Бетонщик   \n",
       "1  130222              Руководитель интернет-проекта (обувь)   \n",
       "2  121331                                   Врач-офтальмолог   \n",
       "3   30170                   Специалист аналитического отдела   \n",
       "4   43059  Руководитель проекта лаборатории нефтехимическ...   \n",
       "\n",
       "                   employment     schedule  \\\n",
       "0            Полная занятость  Полный день   \n",
       "1            Полная занятость  Полный день   \n",
       "2            Полная занятость  Полный день   \n",
       "3  Проектная/Временная работа  Полный день   \n",
       "4            Полная занятость  Полный день   \n",
       "\n",
       "                                         description experience    contract  \\\n",
       "0  <p>В Компанию с центральным офисом в Москве (в...   1-3 года  постоянный   \n",
       "1  <p><strong>Должностные обязанности:</strong></...    3-6 лет  постоянный   \n",
       "2  <p><strong>Обязанности:</strong></p> <ul> <li>...    3-6 лет  постоянный   \n",
       "3  <p><strong>Обязанности:</strong></p> <ul> <li>...   1-3 года  постоянный   \n",
       "4  <p>Руководитель проекта лаборатории нефтехимич...   1-3 года  постоянный   \n",
       "\n",
       "   low_sal  high_sal  no_sal_data  \n",
       "0        0         0            1  \n",
       "1    50000     70000            0  \n",
       "2        0         0            1  \n",
       "3        0         0            1  \n",
       "4        0         0            1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Creating one-hot features for category columns\n",
    "\n",
    "def make_bin_cols(table_data):\n",
    "   pass \n",
    "\n",
    "col_names = ['employment','schedule','experience','contract']\n",
    "dt_bin = pd.DataFrame()\n",
    "dt = dt_all[col_names]\n",
    "j = 0\n",
    "\n",
    "for j in range(dt.shape[1]):\n",
    "    for row_val in np.unique(dt.iloc[:,j]):\n",
    "        new_col = np.zeros(dt.shape[0])   \n",
    "        new_col[np.array(dt.iloc[:,j] == row_val)] = 1\n",
    "        col_name = dt.columns.values[j] + \"_\" + row_val\n",
    "        dt_bin[col_name] = new_col\n",
    "        \n",
    "dt_all = dt_all.join(dt_bin)\n",
    "dt_all = dt_all.drop(col_names, axis =1 )\n",
    "##pd.Series(np.unique(dt_all['employment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_str(mystr):\n",
    "    text = re.sub(u\"<.*?>\",\"\", mystr)\n",
    "    text = re.sub(u\"&quot;\",\"\", text)\n",
    "    return text\n",
    "    \n",
    "dt_all['description'] = map(clean_str, dt_all['description'])\n",
    "dt_all['job-name'] = map(clean_str, dt_all['job-name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##  nltk.download(\"punkt\")\n",
    "##\n",
    "##  http://www.markhneedham.com/blog/2015/02/15/pythonscikit-learn-calculating-tfidf-on-how-i-met-your-mother-transcripts/\n",
    "##\n",
    "\n",
    "def tokenize(text):\n",
    "    stemmer = SnowballStemmer(\"russian\")\n",
    "    text = re.sub(u\"[^a-zA-Z0-9а-яА-Я -]\",\"\",text)\n",
    "    text = re.sub(u\"--\",\"\",text) \n",
    "    text = re.sub(u\"($-)|( -)|(-^)\",\"\",text)\n",
    "    text = re.sub(u\" 000\",u\"000\",text)\n",
    "\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = []\n",
    "    \n",
    "    for item in tokens:\n",
    "        stems.append(stemmer.stem(item))\n",
    "    return stems\n",
    "\n",
    "\n",
    "def make_tfidf_decomposition (train_dt, test_dt, pca_size):\n",
    "\n",
    "    rus_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "    tfidf = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1, 5), min_df=15, stop_words = rus_stopwords)\n",
    "\n",
    "    tfs_train = tfidf.fit_transform(train_dt)\n",
    "    tfs_test  = tfidf.transform(test_dt)\n",
    "\n",
    "    pca_tf = PCA(n_components = pca_size)\n",
    "    ## pca_tf = TSNE(n_components = pca_size)\n",
    "\n",
    "    tfs_train = pd.DataFrame(pca_tf.fit_transform (tfs_train.todense()))\n",
    "    tfs_test  = pd.DataFrame(pca_tf.transform (tfs_test.todense()))\n",
    "    \n",
    "    feature_names = pd.Series(tfidf.get_feature_names())\n",
    "\n",
    "    return tfs_train, tfs_test, feature_names\n",
    "\n",
    "# pd.set_option('display.max_rows', 1000)\n",
    "# print feature_names\n",
    "# pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Create TFIDF vectors from description data\n",
    "##\n",
    "\n",
    "n_shape = dt_all.shape[0]/2\n",
    "n_shape\n",
    "descr_train, descr_test, feat_name = make_tfidf_decomposition (dt_all['description'][0:n_shape], dt_all['description'][n_shape:], pca_size = 200)\n",
    "\n",
    "descr_train.columns = map (lambda x: 'descr ' + (str(x)), descr_train.columns.values)\n",
    "descr_test.columns  = map (lambda x: 'descr ' + (str(x)), descr_test.columns.values)\n",
    "\n",
    "descr_all = pd.concat((descr_train,descr_test),axis=0)\n",
    "descr_all.index = range(descr_all.shape[0])\n",
    "\n",
    "print dt_all.shape\n",
    "\n",
    "dt_all = dt_all.join(descr_all)\n",
    "\n",
    "print descr_all.shape, dt_all.shape\n",
    "\n",
    "## del descr_train, descr_test, descr_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Create TFIDF vectors from job-name data\n",
    "##\n",
    "\n",
    "n_shape = dt_all.shape[0]/2\n",
    "n_shape\n",
    "title_train, title_test, feat_name = make_tfidf_decomposition (dt_all['job-name'][0:n_shape], dt_all['job-name'][n_shape:], pca_size = 30)\n",
    "\n",
    "title_train.columns = map (lambda x: 'title ' + (str(x)), title_train.columns.values)\n",
    "title_test.columns  = map (lambda x: 'title ' + (str(x)), title_test.columns.values)\n",
    "\n",
    "title_all = pd.concat((title_train, title_test),axis=0)\n",
    "title_all.index = range(title_all.shape[0])\n",
    "\n",
    "dt_all = dt_all.join(title_all)\n",
    "\n",
    "del title_train, title_test, title_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## look at feature names\n",
    "##\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "print feat_name\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## generate bool index columns with special words:\n",
    "\n",
    "special_words = [u\"руковод\",u\"медиа\",u\"маркетин\",u\"автомоб\",u\"машин\",u\"юрист\",u\"бухгалт\",u\"страхова\",u\"менедж\",u\"продаж\",u\"реклам\"]\n",
    "special_words = special_words + [u'инженер',u'анлгийск',u'english',u'лаборат',u'исследов',u'медицин',u'программ',u'риск','финанс']\n",
    "special_words = special_words + [u'закуп',u'снабжен',u'кассир',u'дизайнер',u'архитектур',u'строитель',u'туризм',u'логист']\n",
    "special_words = special_words + [u'страхов']\n",
    "\n",
    "\n",
    "for i_word in special_words:\n",
    "    new_col = np.zeros(dt_all.shape[0])\n",
    "    tt = map (lambda x: re.search(i_word, x.lower())==None, dt_all['job-name'])\n",
    "    tt = ~np.array(tt)\n",
    "    new_col[tt] = 1\n",
    "    col_name = \"job-name \" + i_word\n",
    "    dt_all[col_name] = new_col\n",
    "    \n",
    "    new_col = np.zeros(dt_all.shape[0])\n",
    "    tt = map (lambda x: re.search(i_word, x.lower())==None, dt_all['description'])\n",
    "    tt = ~np.array(tt)\n",
    "    new_col[tt] = 1\n",
    "    col_name = \"description \" + i_word\n",
    "    dt_all[col_name] = new_col    \n",
    "\n",
    "dt_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "progs = [u\"1с бухгалтерия\",u\"office\",u\"MS office\",u\"excel\",u\"word\",\"outlook\",u'autocad',u'Adobe Illustrator']\n",
    "progs = progs + [u'Photoshop', u'Corel Draw', u'PHP', u'КАСКО', u'ОСАГО', u'ДГО']\n",
    "\n",
    "\n",
    "tt =re.search(u\"1с бухгалтерия\".lower(), dt_all.loc[test_index[i],\"description\"].lower())\n",
    "print tt\n",
    "\n",
    "for i_word in progs:\n",
    "    new_col = np.zeros(dt_all.shape[0])\n",
    "    tt = map (lambda x: re.search(i_word.lower(), x.lower())==None, dt_all['job-name'])\n",
    "    tt = ~np.array(tt)\n",
    "    new_col[tt] = 1\n",
    "    col_name = \"job-name \" + i_word.lower()\n",
    "    dt_all[col_name] = new_col\n",
    "    \n",
    "    new_col = np.zeros(dt_all.shape[0])\n",
    "    tt = map (lambda x: re.search(i_word.lower(), x.lower())==None, dt_all['description'])\n",
    "    tt = ~np.array(tt)\n",
    "    new_col[tt] = 1\n",
    "    col_name = \"description \" + i_word.lower()\n",
    "    dt_all[col_name] = new_col    \n",
    "\n",
    "dt_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = dt_all.copy(deep = True)\n",
    "print X.shape\n",
    "print dt_all.shape\n",
    "\n",
    "ids = dt_all['id']\n",
    "X = X.drop(['id','job-name','description'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(y_class == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Changing values in y_class to class numbers and lists\n",
    "## i.e. from [0,1,0,1,0,0,1 ... ] to [2,4,7,..]\n",
    "##\n",
    "\n",
    "def makePredictionList(Ypred):\n",
    "    Ypred = np.vstack(Ypred)\n",
    "    Ypred = np.transpose(Ypred)\n",
    "    Ypred = map (lambda tt: Ypred[tt,Ypred[tt,:]!=0].astype(int).tolist(), range(Ypred.shape[0])) \n",
    "    return Ypred\n",
    "\n",
    "\n",
    "y_class_vals = pd.DataFrame(index=range(y_class.shape[0]))\n",
    "Ytrue = []\n",
    "\n",
    "for i_col in range(y_class.shape[1]):\n",
    "    col_name = y_class.columns.values[i_col]\n",
    "    new_col = np.zeros(y_class.shape[0])\n",
    "    new_col[np.array(y_class.loc[:,col_name]==1)] = i_col + 1\n",
    "    Ytrue.append(new_col)\n",
    "\n",
    "Ytrue = makePredictionList (Ytrue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Count number of categories for each id\n",
    "##\n",
    "\n",
    "num_cat_list = map (lambda tt: len(Ytrue[tt]), range(len(Ytrue)))\n",
    "\n",
    "for k in np.unique(num_cat_list):\n",
    "    print k, sum(num_cat_list==k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "## sorting probas and return top_2\n",
    "def getTopClassByProba (prob_list, top_num):\n",
    "    \n",
    "    tt = prob_list\n",
    "    tt = zip(np.arange(1,len(tt)+1),tt)\n",
    "    top_2 = sorted(tt,key=operator.itemgetter(1),reverse=True)[0:top_num]\n",
    "    top_2 = pd.DataFrame(top_2)[0].tolist()\n",
    "    return top_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## based on Yprob matrix and ytrue real classes return threshold to maximize f1 statistic\n",
    "##\n",
    "\n",
    "def getBestProbVals(Yproba, y_true):\n",
    "    num_class = y_true.shape[1]\n",
    "\n",
    "    prob_arr = np.zeros(num_class)\n",
    "    fmax_arr = np.zeros(num_class)\n",
    "\n",
    "    for t_cat in range(num_class):\n",
    "        Ytrainproba = pd.DataFrame(Yproba)\n",
    "        col_prob = Yproba.iloc[:,t_cat]\n",
    "        fmax = 0\n",
    "        prob_best = 0\n",
    "        for p_prob in np.arange(0,1,0.01):\n",
    "            col_class = np.array(col_prob>p_prob).astype(int)\n",
    "            col_f1_score = f1_score(y_true.iloc[:,t_cat], col_class)\n",
    "            if col_f1_score > fmax:\n",
    "                prob_best = p_prob\n",
    "                fmax = col_f1_score\n",
    "            ## print p_prob, col_f1_score\n",
    "\n",
    "        ## print prob_best, fmax\n",
    "        prob_arr[t_cat] = prob_best\n",
    "        fmax_arr[t_cat] = fmax\n",
    "\n",
    "    return prob_arr, fmax_arr \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert predicted probas (y_prob) to classes if they are greater then predefined values in prob_arr \n",
    "##\n",
    "\n",
    "def probasToClasses(y_prob, prob_arr):\n",
    "    class_filt = y_prob>prob_arr\n",
    "    classes = np.arange(1,len(y_prob)+1)[class_filt].tolist()\n",
    "    return classes\n",
    "\n",
    "\n",
    "##map (lambda x: probasToClasses(Yproba[x,],prob_arr) ,range(Yproba.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###  Making data classification:\n",
    "###\n",
    "###  1. doing standard xgboost classification on each class separately\n",
    "###  2. Using class probas to estimate effective probability threshold for each class.\n",
    "###  3. Estimating classes from threshold\n",
    "###  4. If set of classes is empty for eany id then best two classes are used\n",
    "###\n",
    "\n",
    "\n",
    "Ypred  = []\n",
    "Yproba = []\n",
    "Ytrainproba = []\n",
    "\n",
    "\n",
    "train_test_split = StratifiedShuffleSplit(y_class.iloc[:,0], n_iter = 1, test_size = 0.3)\n",
    "\n",
    "for train_index, test_index in train_test_split:\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    y_train_all, y_test_all = y_class.iloc[train_index,:], y_class.iloc[test_index,:]\n",
    "    \n",
    "    \n",
    "    for t_cat in  range(y_class.shape[1]):\n",
    "\n",
    "        y_train, y_test = y_train_all.iloc[:,t_cat], y_test_all.iloc[:,t_cat]\n",
    "\n",
    "#         clf = ExtraTreesClassifier (n_estimators= 200, min_samples_leaf=5)\n",
    "#         clf = RandomForestClassifier (n_estimators= 200, min_samples_leaf=5, n_jobs = -1)\n",
    "\n",
    "        clf = xgb.XGBClassifier(missing=np.nan, max_depth=5, n_estimators=310, \n",
    "                                learning_rate=0.03, nthread=8, subsample=0.95, colsample_bytree=0.85, seed=4242)\n",
    "        \n",
    "        clf.fit(X_train,y_train)\n",
    "        y_train_proba = clf.predict_proba(X_train)\n",
    "        \n",
    "        y_proba = clf.predict_proba(X_test)\n",
    "        y_pred = y_proba[:,1]>0.2\n",
    "        y_pred = y_pred.astype(int)\n",
    "        y_pred [y_pred==1] = t_cat+1\n",
    "        \n",
    "        Ypred.append(y_pred)\n",
    "        Yproba.append(y_proba[:,1])\n",
    "        Ytrainproba.append(y_train_proba[:,1])\n",
    "    \n",
    "    Yproba = np.vstack(Yproba)\n",
    "    Yproba = np.transpose(Yproba)\n",
    "    \n",
    "    Ytrainproba = np.vstack(Ytrainproba)\n",
    "    Ytrainproba = np.transpose(Ytrainproba)\n",
    "    Ytrainproba = pd.DataFrame(Ytrainproba)\n",
    "    \n",
    "    prob_arr, fmax_arr = getBestProbVals(Ytrainproba, y_train_all)\n",
    "    Ypred = map (lambda x: probasToClasses(Yproba[x,],prob_arr) ,range(Yproba.shape[0]))\n",
    "    \n",
    "    # replace null answers with top 2\n",
    "    for k in range(len(Ypred)):\n",
    "        if len(Ypred[k]) == 0:\n",
    "            Ypred[k] = getTopClassByProba (Yproba[k,:], 2)\n",
    "    \n",
    "    \n",
    "    ## Ypred = map (lambda x: getTopClassByProba(Yproba[x,:], 2),range(Yproba.shape[0]))\n",
    "\n",
    "    Ytrue_test = np.array(Ytrue)[test_index].tolist()\n",
    "\n",
    "    print mean_f1 (Ytrue_test,Ypred)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ypred  = []\n",
    "\n",
    "for t_cat in  range(y_class.shape[1]):\n",
    "    \n",
    "    y_train, y_test = y_train_all.iloc[:,t_cat], y_test_all.iloc[:,t_cat]\n",
    "    \n",
    "    clf = RandomForestClassifier (n_estimators= 200, min_samples_leaf=5, n_jobs = -1)\n",
    "    clf.fit (Ytrainproba, y_train)\n",
    "    y_pred = clf.predict(Yproba)\n",
    "    y_pred [y_pred==1] = t_cat+1\n",
    "    Ypred.append(y_pred)\n",
    "    Ynew_proba = clf.predict_proba(Yproba)\n",
    "    \n",
    "\n",
    "Ypred = makePredictionList(Ypred)\n",
    "\n",
    "Ynew_proba = np.vstack(Ynew_proba)\n",
    "Ynew_proba = np.transpose(Ynew_proba)\n",
    "\n",
    "for k in range(len(Ypred)):\n",
    "    if len(Ypred[k]) == 0:\n",
    "        Ypred[k] = getTopClassByProba (Yproba[k,:], 2)\n",
    "        \n",
    "print mean_f1 (Ytrue_test,Ypred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print len(Ytrue_test)\n",
    "print len(Ypred)\n",
    "\n",
    "# print zip(np.arange(1,len(Yproba[i])),prob_arr)\n",
    "# print probasToClasses(Yproba[0,:],prob_arr)\n",
    "print \"\"\n",
    "\n",
    "for i in range(20):\n",
    "    print Ytrue_test[i],Ypred[i],zip(np.arange(1,len(Yproba[i])),Yproba[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 188\n",
    "print Ytrue_test[i],Ypred[i],zip(np.arange(1,len(Yproba[i])+1),Yproba[i])\n",
    "test_index[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dt_all.loc[test_index[i],\"job-name\"]\n",
    "print dt_all.loc[test_index[i],\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_class.iloc[test_index[i],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dt_all.loc[test_index[i],\"description\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
